# -*- coding: utf-8 -*-
"""accept-new-donors-and-get-donor-list.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1570h7w9H8nljXxTx1whTaMqH78laZ8Gu
"""

# %% load in required libraries
import pandas as pd
import datetime as dt
import numpy as np
import os
import sys
import requests
import json
envPath = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if envPath not in sys.path:
    sys.path.insert(0, envPath)
import environmentalVariables

def login_api(auth):
    url1 = "https://api.tidepool.org/auth/login"
    myResponse = requests.post(url1, auth=auth)
    if(myResponse.ok):
        xtoken = myResponse.headers["x-tidepool-session-token"]
        userid = json.loads(myResponse.content.decode())["userid"]
        headers = {
            "x-tidepool-session-token": xtoken,
            "Content-Type": "application/json"
        }

    else:
        print(auth[0], "ERROR", myResponse.status_code)
        sys.exit("Error with " + auth[0] + ":" + str(myResponse.status_code))

    return xtoken, userid, headers

def accept_new_donor(auth):
    nAccepted = 0
#    url1 = "https://api.tidepool.org/auth/login"
    url3 = "https://api.tidepool.org/auth/logout"
#    myResponse = requests.post(url1, auth=auth)
    xtoken, userid, headers = login_api(auth)

#    if(myResponse.ok):
#        xtoken = myResponse.headers["x-tidepool-session-token"]
#        userid = json.loads(myResponse.content.decode())["userid"]
#
#        headers = {
#            "x-tidepool-session-token": xtoken,
#            "Content-Type": "application/json"
#        }

    url2 = "https://api.tidepool.org/confirm/invitations/" + userid
    myResponse2 = requests.get(url2, headers=headers)
    if(myResponse2.ok):

        usersData = json.loads(myResponse2.content.decode())

        for i in range(0, len(usersData)):
            shareKey = usersData[i]["key"]
            shareID = usersData[i]["creatorId"]
            payload = {
                "key": shareKey
            }

            url3 = "https://api.tidepool.org/confirm/accept/invite/" + \
                userid + "/" + shareID

            myResponse3 = requests.put(url3, headers=headers, json=payload)

            if(myResponse3.ok):
                nAccepted = nAccepted + 1
            else:
                print(auth[0], "ERROR", myResponse3.status_code)
                sys.exit("Error with " + auth[0] + ":" + str(myResponse3.status_code))
    elif myResponse2.status_code == 404:
        # this is the case where there are no new invitations
        print("very likely that no new invitations exist")
    else:
        print(auth[0], "ERROR", myResponse2.status_code)
        sys.exit("Error with " + auth[0] + ":" + str(myResponse2.status_code))
#    else:
#        print(auth[0], "ERROR", myResponse.status_code)
#        sys.exit("Error with " + auth[0] + ":" + str(myResponse.status_code))

    myResponse3 = requests.post(url3, auth=auth)

#    responses = [myResponse, myResponse2, myResponse3]

    return nAccepted  #, responses


def get_donor_list(auth):
    url1 = "https://api.tidepool.org/auth/login"
    url3 = "https://api.tidepool.org/auth/logout"
    myResponse = requests.post(url1, auth=auth)

    if(myResponse.ok):
        xtoken = myResponse.headers["x-tidepool-session-token"]
        userid = json.loads(myResponse.content.decode())["userid"]
        url2 = "https://api.tidepool.org/access/groups/" + userid
        headers = {
            "x-tidepool-session-token": xtoken,
            "Content-Type": "application/json"
        }

        myResponse2 = requests.get(url2, headers=headers)
        if(myResponse2.ok):

            donors_list = json.loads(myResponse2.content.decode())

        else:
            print(auth[0], "ERROR", myResponse2.status_code)
            sys.exit("Error with API2 for " + auth[0] + ":" + str(myResponse2.status_code))

    else:
        print(auth[0], "ERROR", myResponse.status_code)
        sys.exit("Error with API1 for " + auth[0] + ":" + str(myResponse.status_code))

    myResponse3 = requests.post(url3, auth=auth)

    responses = [myResponse, myResponse2, myResponse3]

    df = pd.DataFrame(list(donors_list.keys()), columns=["userID"])

    return df, responses


# create output folders
current_dateStamp = dt.datetime.now().strftime("%Y-%m-%d")
phiDateStamp = "PHI-" + current_dateStamp
donorFolder = os.path.join("..", "data", phiDateStamp + "-donor-data")
if not os.path.exists(donorFolder):
    os.makedirs(donorFolder)

donorListFolder = os.path.join(donorFolder, phiDateStamp + "-donorLists")
if not os.path.exists(donorListFolder):
    os.makedirs(donorListFolder)

uniqueDonorPath = os.path.join(
    donorFolder,
    phiDateStamp + "-uniqueDonorList.csv"
)

csv_path = os.path.join(
    donorFolder,
    phiDateStamp + "-donorCsvData"
)

if not os.path.exists(csv_path):
    os.makedirs(csv_path)

# define the donor groups
donor_groups = [
    "bigdata",
    "AADE",
    "BT1",
    "carbdm",
    "CDN",
    "CWD",
    "DHF",
    "DIATRIBE",
    "diabetessisters",
    "DYF",
    "JDRF",
    "NSF",
    "T1DX",
]
all_donors_df = pd.DataFrame(columns=["userID", "donorGroup"])

# accounts to ignore (QA testing)
accounts_to_ignore = [
    'f597f21dcd', '0ef51a0121', '38c3795fcb', '69c99b51f6', '84c2cdd947',
    '9cdebdc316', '9daaf4d4c1', 'bdf4724bed', 'c7415b5097', 'dccc3baf63',
    'ee145393b0', '00cd0ffada', '122a0bf6c5', '898c3d8056', '9e4f3fbc2a',
    '1ebe2a2790', '230650bb9c', '3f8fdabcd7', '636aad0f58', '70df39aa43',
    '92a3c903fe', '3043996405', '0239c1cfb2', '03852a5acc', '03b1953135',
    '0ca5e75e4a', '0d8bdb05eb', '19123d4d6a', '19c25d34b5', '1f6866bebc',
    '1f851c13a5', '275ffa345f', '275ffa345f', '3949134b4a', '410865ba56',
    '57e2b2ed3d', '59bd6891e9', '5acf17a80a', '627d0f4bf1', '65247f8257',
    '6e5287d4c4', '6fc3a4ad44', '78ea6c3cad', '7d8a80e8ce', '8265248ea3',
    '8a411facd2', '98f81fae18', '9d601a08a3', 'aa9fbc4ef5', 'aaac56022a',
    'adc00844c3', 'aea4b3d8ea', 'bc5ee641a3', 'c8328622d0', 'cfef0b91ac',
    'df54366b1c', 'e67aa71493', 'f2103a44d5', 'dccc3baf63'
]

for donor_group in donor_groups:
    if donor_group == "bigdata":
        dg = ""
    else:
        dg = donor_group

    nNewDonors = accept_new_donor(
        environmentalVariables.get_environmental_variables(dg)
    )
    print(nNewDonors, "new donors for ", donor_group)

    # get full donor list
    print("now getting full donor list...")
    donors_df, api_response_donor = get_donor_list(
        environmentalVariables.get_environmental_variables(dg)
    )
    donors_df["donorGroup"] = donor_group
    print(donor_group, "complete")
    all_donors_df = pd.concat([all_donors_df, donors_df])

all_donors_df.sort_values(by=['userID', 'donorGroup'], inplace=True)
uniqueDonors = all_donors_df.loc[~all_donors_df["userID"].duplicated()]
total_donors = len(set(uniqueDonors["userID"]) - set(accounts_to_ignore))
real_donors = pd.DataFrame(
    set(uniqueDonors["userID"]) - set(accounts_to_ignore),
    columns=["userID"]
)
real_donors = pd.merge(real_donors, uniqueDonors, how="left", on="userID")
real_donors.sort_values(by="donorGroup", inplace=True)
real_donors.reset_index(drop=True, inplace=True)
real_donors.to_csv(uniqueDonorPath, index_label=False)

print("There are ", total_donors, " total donors,")
print("after removing donors that donated to more than 1 group,")
print("and after removing QA testing accounts.")


# %% loop through each user and get data
current_dateStamp = dt.datetime.now().strftime("%Y-%m-%d")
phiDateStamp = "PHI-" + current_dateStamp
donorFolder = os.path.join("..", "data", phiDateStamp + "-donor-data")
if not os.path.exists(donorFolder):
    os.makedirs(donorFolder)

donorListFolder = os.path.join(donorFolder, phiDateStamp + "-donorLists")
if not os.path.exists(donorListFolder):
    os.makedirs(donorListFolder)

uniqueDonorPath = os.path.join(
    donorFolder,
    phiDateStamp + "-uniqueDonorList.csv"
)


csv_path = os.path.join(
    donorFolder,
    phiDateStamp + "-donorCsvData"
)

if not os.path.exists(csv_path):
    os.makedirs(csv_path)


donor_list = pd.read_csv(uniqueDonorPath, low_memory=False)
url1 = "https://api.tidepool.org/auth/login"
url3 = "https://api.tidepool.org/auth/logout"

meta_df = pd.DataFrame(
    dtype=object,
    columns=[
        "diagnosisType",
        "diagnosisDate",
        "biologicalSex",
        "birthday",
        "targetTimezone",
        "targetDevices",
        "isOtherPerson",
        "about"
    ]
)

for donor_group in donor_list["donorGroup"].unique():
    if donor_group == "bigdata":
        dg = ""
    else:
        dg = donor_group

    response1 = requests.post(
        url1,
        auth=environmentalVariables.get_environmental_variables(dg)
    )
    if(response1.ok):
        xtoken = response1.headers["x-tidepool-session-token"]
        headers = {
            "x-tidepool-session-token": xtoken,
            "Content-Type": "application/json"
        }

        for userid in donor_list.loc[donor_list["donorGroup"] == donor_group, "userID"]:
            profile_api = "https://api.tidepool.org/metadata/%s/profile" % userid
            responseP = requests.get(profile_api, headers=headers)
            if(responseP.ok):
                user_profile = json.loads(responseP.content.decode())
                if "patient" in user_profile.keys():
                    temp_df = pd.DataFrame.from_dict(
                        user_profile["patient"],
                        dtype=object,
                        orient='index',
                        columns=[userid]
                    ).T

                    # get download json data
                    endDate = pd.datetime.now()
                    weeks_of_data=52*2
                    years_of_data = int(np.floor(weeks_of_data/52))
                    df = pd.DataFrame()

                    gzip_csv_output_path = os.path.join(
                        csv_path,
                        "PHI-" + userid + ".gz"
                    )

                    for years in range(0, years_of_data + 1):

                        startDate = endDate - pd.Timedelta(365, unit="d")

                        url2 = (
                            "https://api.tidepool.org/data/" + userid + "?" +
                            "endDate=" + endDate.strftime("%Y-%m-%d") + "T23:59:59.000Z" + "&" +
                            "startDate=" + startDate.strftime("%Y-%m-%d") + "T00:00:00.000Z" + "&" +
                            "dexcom=true" + "&" +
                            "medtronic=true" + "&" +
                            "carelink=true"
                        )

                        myResponse2 = requests.get(url2, headers=headers)
                        if(myResponse2.ok):
                            json_data = json.loads(myResponse2.content.decode())
                            year_df = pd.DataFrame(json_data)
                            df = pd.concat(
                                [df, year_df],
                                ignore_index=True,
                                sort=False
                            )

                        else:
                            print("ERROR in getting data for year ", years, myResponse2.status_code)

                        endDate = startDate - pd.Timedelta(1, unit="d")
                    df_size = len(df)

                    if df_size > 0:
                        df.to_csv(gzip_csv_output_path, index_label=False, compression="gzip")
                        meta_df["nCols"] = df_size
                    else:
                        meta_df["nCols"] = 0
                    meta_df = pd.concat([meta_df, temp_df], sort=False)

                    print("done with", userid,"data size is", df_size)
            else:
                print("ERROR in metadata API ", responseP.status_code)
    else:
        print("ERROR in getting token ", response1.status_code)
        response2 = np.nan

    response3 = requests.post(
        url3,
        auth=environmentalVariables.get_environmental_variables(dg)
    )
    print("done with donor group", donor_group)
    print("here are the responses", response1, responseP, response3)

# add the meta data to the donor data
meta_df.reset_index(inplace=True)
meta_df.rename(columns={"index": "userID"}, inplace=True)
donor_list = pd.merge(
    donor_list,
    meta_df,
    how="left",
    on="userID"
)
